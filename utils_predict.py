import os
import pickle
import joblib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from keras import layers, models
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding, Dense, LSTM, SimpleRNN, Bidirectional, GRU, Conv1D, GlobalMaxPooling1D

# =================================== #
# ===== Hu·∫•n luy·ªán m√¥ h√¨nh LSTM ===== #
# =================================== #
def train_LSTM_My_SAV(X_train, X_test, y_train, y_test,
    max_words=10000,
    embedding_dim=100,
    max_seq_length=100,
    lstm_units=64, # 128 ƒë·ªëi v·ªõi d·ªØ li·ªáu tr√™n 22k d√≤ng
    dense_units=64,
    learning_rate=0.0001,
    batch_size=32, # 64 ƒë·ªëi v·ªõi d·ªØ li·ªáu tr√™n 22k d√≤ng
    epochs=100,
    runs=1,
    accuracy_save=94.80,
    save_dir="model/My_LSTM_"):
    
    sl = 0  # s·ªë l·∫ßn tr√™n 95%

    for i in range(1, runs + 1):
        # Build model
        model = Sequential()
        model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_seq_length, trainable=True, mask_zero=True))
        model.add(LSTM(lstm_units))
        model.add(Dense(dense_units, activation='relu'))
        model.add(Dense(1, activation='sigmoid'))

        optimizer = Adam(learning_rate=learning_rate)
        early_stopping = EarlyStopping(monitor='val_loss', patience=5)

        model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

        print(f"\nüîÑ Ch·∫°y l·∫ßn th·ª© {i}/{runs} ...")

        history = model.fit(X_train, y_train,
            validation_split=0.1,
            batch_size=batch_size,
            epochs=epochs,
            callbacks=[early_stopping], verbose=0)

        score = model.evaluate(X_test, y_test, verbose=0)
        accuracy_percentage = score[1] * 100

        print(f"L∆∞·ª£t ch·∫°y l·∫ßn th·ª©: {i}")
        print(f"üéØ Accuracy: {accuracy_percentage:.2f}%")

        # N·∫øu accuracy ‚â• threshold th√¨ l∆∞u
        if accuracy_percentage >= accuracy_save:
            sl += 1
            os.makedirs("model/", exist_ok=True)

            score_path = f"{save_dir}score_{accuracy_percentage:.2f}.npy"
            np.save(score_path, score)
            model_path = f"{save_dir}model_{accuracy_percentage:.2f}.h5"
            model.save(model_path)
            history_path = f"{save_dir}history_{accuracy_percentage:.2f}.pkl"
            save_history(history, history_path)
            print(f"üìÅ ƒê√£ l∆∞u model ƒë·∫°t {accuracy_percentage:.2f}% v√†o th∆∞ m·ª•c.")

    tl = (sl / runs) * 100
    print(f"\nüìå K·∫øt qu·∫£ cu·ªëi c√πng:")
    print(f"S·ªë l·∫ßn ƒë·∫°t ƒë·ªô ch√≠nh x√°c ‚â• {accuracy_save}%: {sl}/{runs}")
    print(f"T·ªâ l·ªá: {tl:.2f}%")

# ============================================== #
# ===== H√†m l∆∞u history hu·∫•n luy·ªán m√¥ h√¨nh ===== #
# ============================================== #
# H√†m l∆∞u history v√†o c√°c t·∫≠p tin
def save_history(history, history_filename):
    with open(history_filename, 'wb') as file:
        pickle.dump(history, file)

# =============================================== #
# ===== H√†m load history hu·∫•n luy·ªán m√¥ h√¨nh ===== #
# =============================================== #
def load_history(history_filename):
    with open(history_filename, 'rb') as file:
        history = pickle.load(file)
    return history

# ============================================= #
# ===== H√†m v·∫Ω bi·ªÉu ƒë·ªì hu·∫•n luy·ªán m√¥ h√¨nh ===== #
# ============================================= #
import matplotlib.pyplot as plt
import os

def draw_chart(model_name, history, score, save_dir="charts"):
    os.makedirs(save_dir, exist_ok=True)

    # ƒê√°nh gi√° m√¥ h√¨nh
    test_loss = score[0]
    test_accuracy = score[1]
    print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')

    # ===================== #
    # 1Ô∏è‚É£ BI·ªÇU ƒê·ªí TRAIN / VAL RI√äNG
    # ===================== #
    plt.figure(figsize=(12, 4))

    # Train
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Loss')
    plt.plot(history.history['accuracy'], label='Accuracy')
    plt.title('T·∫≠p Train')
    plt.xlabel('Epoch')
    plt.legend()

    # Validation
    plt.subplot(1, 2, 2)
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title('T·∫≠p Validation')
    plt.xlabel('Epoch')
    plt.legend()

    file1 = f"{save_dir}/train_val_overview.png"
    plt.savefig(file1, dpi=300, bbox_inches='tight')
    plt.show()

    print(f"üìÅ ƒê√£ l∆∞u file train_val_overview.png")

    # ===================== #
    # 2Ô∏è‚É£ BI·ªÇU ƒê·ªí SO S√ÅNH LOSS / ACC
    # ===================== #
    plt.figure(figsize=(12, 4))

    # Loss comparison
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.title('Loss Comparison')
    plt.xlabel('Epoch')
    plt.legend()

    # Accuracy comparison
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.title('Accuracy Comparison')
    plt.xlabel('Epoch')
    plt.legend()

    file2 = f"{save_dir}/loss_accuracy_comparison.png"
    plt.savefig(file2, dpi=300, bbox_inches='tight')
    plt.show()

    print(f"üìÅ ƒê√£ l∆∞u file loss_accuracy_comparison.png")

def draw_chart_1(model, history, score):
    # ƒê√°nh gi√° m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm th·ª≠ ƒë·ªÉ l·∫•y th√¥ng tin v·ªÅ loss v√† accuracy
    test_loss = score[0]
    test_accuracy = score[1]

    print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')

    # V·∫Ω bi·ªÉu ƒë·ªì loss v√† accuracy t·ª´ history
    plt.figure(figsize=(12, 4))

    # Bi·ªÉu ƒë·ªì loss
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Loss')
    plt.plot(history.history['accuracy'], label='Accuracy')

    plt.title('T·∫≠p Train')
    plt.xlabel('Epoch')
    plt.legend()

    # Bi·ªÉu ƒë·ªì loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['val_loss'], label='Val Loss')
    plt.plot(history.history['val_accuracy'], label='Val Accuracy')

    plt.title('T·∫≠p Val')
    plt.xlabel('Epoch')
    plt.legend()

    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
    plt.show()

    # V·∫Ω bi·ªÉu ƒë·ªì loss v√† accuracy t·ª´ history
    plt.figure(figsize=(12, 4))

    # Bi·ªÉu ƒë·ªì loss train
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Train Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')

    plt.title('Loss Comparison')
    plt.xlabel('Epoch')
    plt.legend()

    # Bi·ªÉu ƒë·ªì accuracy train
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')

    plt.title('Accuracy Comparison')
    plt.xlabel('Epoch')
    plt.legend()

    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
    plt.show()

# ========================================== #
# ===== H√†m d·ª± ƒëo√°n c·∫£m x√∫c m·ªôt review ===== #
# ========================================== #
# * max_words = 10.000 (t·ªët nh·∫•t. C·∫•u h√¨nh m√°y t√≠nh kh√¥ng ƒë√°p ·ª©ng n√™n ch·ªçn 2500)
# - Tokenzier s·∫Ω ch·ªâ gi·ªØ l·∫°i 10.000 t·ª´ xu·∫•t hi·ªán nhi·ªÅu nh·∫•t trong to√†n b·ªô d·ªØ li·ªáu.
# - T·∫•t c·∫£ t·ª´ c√≤n l·∫°i ‚Üí ƒë∆∞·ª£c g√°n th√†nh token OOV (Out-Of-Vocabulary).

# * max_seq_length = 100
# - ƒê·ªô d√†i t·ªëi ƒëa c·ªßa m·ªói c√¢u (chu·ªói s·ªë) khi ƒë∆∞a v√†o LSTM.
# - M·ªói c√¢u sau khi chuy·ªÉn th√†nh chu·ªói s·ªë c√≥ ƒë·ªô d√†i kh√¥ng ƒë∆∞·ª£c v∆∞·ª£t qu√° 100 token.
# - N·∫øu c√¢u qu√° d√†i ‚Üí c·∫Øt b·ªõt t·ª´ ƒë·∫ßu ho·∫∑c cu·ªëi ƒë·ªÉ c√≤n 100.
# - N·∫øu c√¢u qu√° ng·∫Øn ‚Üí pad th√™m s·ªë 0 cho ƒë·ªß 100.
# ============================================================================ #
# ===== V·ªõi padding="post" v√† truncating="post" ===== #
# ===== B·∫Øt bu·ªôc khi Embedding hu·∫•n luy·ªán m√¥ h√¨nh ph·∫£i c√≥ mask_zero=True ===== #
# ============================================================================ #
def process_X_token_review(new_review, vt='post', tokenizer_path = "input/tokenizer.joblib"):
    max_seq_length = 100

    # 1Ô∏è‚É£ Load ho·∫∑c t·∫°o tokenizer
    if os.path.exists(tokenizer_path):
        tokenizer = joblib.load(tokenizer_path)
    else:
        print("Kh√¥ng t√¨m th·∫•y file tokenizer.joblib")

    # 2Ô∏è‚É£ Text ‚Üí sequence
    sequences = tokenizer.texts_to_sequences([new_review])

    # 3Ô∏è‚É£ Pad gi·ªëng l√∫c train
    X_token = pad_sequences(sequences, maxlen=max_seq_length, padding=vt, truncating=vt)
    return X_token

def process_X_token_csv(review_token, vt='post', tokenizer_path = "input/tokenizer.joblib"):
    max_words = 10000
    max_seq_length = 100

    # 1Ô∏è‚É£ Load ho·∫∑c t·∫°o tokenizer
    if os.path.exists(tokenizer_path):
        tokenizer = joblib.load(tokenizer_path)
    else:
        tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
        tokenizer.fit_on_texts(review_token)
        joblib.dump(tokenizer, tokenizer_path)

    # 2Ô∏è‚É£ Text ‚Üí sequence
    sequences = tokenizer.texts_to_sequences(review_token)

    # 3Ô∏è‚É£ Pad gi·ªëng l√∫c train
    X_token = pad_sequences(sequences, maxlen=max_seq_length, padding=vt, truncating=vt)
    return X_token

def predict_score(model, X_token):
    score = model.predict(X_token)[0]
    return score

def predict_sentiment(score):
    if score > 0.5:
        return 'positive'
    elif score < 0.5:
        return 'negative'
    else:
        return 'neutral'

# =========================================================== #
# ===== H√†m v·∫Ω bi·ªÉu ƒë·ªì th·ªëng k√™ c·∫£m x√∫c sau khi d·ª± ƒëo√°n ===== #
# =========================================================== #
def plot_sentiment_pie():
    file_path = 'input/all_reviews.csv'
    sentiment_data = pd.read_csv(file_path)

    # ƒê·∫øm s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa m·ªói nh√£n
    label_counts = sentiment_data['sentiment'].value_counts()

    # V·∫Ω bi·ªÉu ƒë·ªì h√¨nh tr√≤n th·ªÉ hi·ªán s·ªë l∆∞·ª£ng v√† % v·ªõi labels t·ª´ c·ªôt "Label"
    sentiment_plt = plt.figure(figsize=(4, 3))
    plt.pie(label_counts, autopct=lambda p: 'SL:{:.0f} \n({:.1f}%)'.format(p * sum(label_counts) / 100, p), startangle=140, textprops={'fontsize': 12})
    #plt.title('Ph√¢n ph·ªëi nh√£n trong d·ªØ li·ªáu')
    plt.axis('equal')
    plt.legend(label_counts.index, loc='best')  # ƒê·∫∑t nh√£n v√† v·ªã tr√≠ t·ªët nh·∫•t

    # L∆∞u bi·ªÉu ƒë·ªì d∆∞·ªõi d·∫°ng file jpg
    sentiment_plt.savefig('static/sentiment_plt.png')

# ===================== #
# ===== WordCloud ===== #
# ===================== #
def generate_wordcloud(
    X_token='input/My_review_token.joblib',
    sentiment='input/My_sentiment.joblib',
    save_dir='output/wordclouds',
    dpi=300
):
    tweets = joblib.load(X_token)      # list of list
    labels = joblib.load(sentiment)    # Series or list

    positive_text = []
    negative_text = []

    for tweet, label in zip(tweets, labels):
        tweet_text = ' '.join(tweet)   # list ‚Üí string
        if label == 'positive':
            positive_text.append(tweet_text)
        elif label == 'negative':
            negative_text.append(tweet_text)

    positive_wordcloud = WordCloud(
        width=800, height=400, background_color='white'
    ).generate(' '.join(positive_text))

    negative_wordcloud = WordCloud(
        width=800, height=400, background_color='black', colormap='Reds'
    ).generate(' '.join(negative_text))

    plt.figure(figsize=(12, 6))

    plt.subplot(1, 2, 1)
    plt.imshow(positive_wordcloud, interpolation='bilinear')
    plt.title('Positive Sentiment')
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.imshow(negative_wordcloud, interpolation='bilinear')
    plt.title('Negative Sentiment')
    plt.axis('off')

    # ====== L∆ØU FILE PNG ======
    os.makedirs(save_dir, exist_ok=True)
    filepath = os.path.join(save_dir, 'wordcloud.png')
    plt.savefig(filepath, dpi=dpi, bbox_inches='tight')
    print(f'ƒê√£ l∆∞u wordcloud t·∫°i: {filepath}')

    plt.show()
    plt.close()

# =========================== #
# ===== WordCloud Token ===== #
# =========================== #
def plot_word_occurrences(
    word,
    X_token='input/My_review_token.joblib',
    sentiment='input/My_sentiment.joblib',
    save_dir='output/charts',
    dpi=300
):
    tweets = joblib.load(X_token)
    labels = joblib.load(sentiment)

    word = word.lower()

    occurrences_positive = 0
    occurrences_negative = 0

    for tweet, label in zip(tweets, labels):
        tweet_text = ' '.join(tweet).lower()
        count = tweet_text.count(word)

        if label == 'positive':
            occurrences_positive += count
        elif label == 'negative':
            occurrences_negative += count

    labels_plot = ['Positive', 'Negative']
    counts = [occurrences_positive, occurrences_negative]

    plt.figure(figsize=(6, 4))
    plt.bar(
        labels_plot,
        counts,
        color=['blue', 'red']   # ‚≠ê Positive: v√†ng, Negative: ƒë·ªè
    )
    plt.title(f'T·∫ßn su·∫•t c·ªßa t·ª´ "{word}" theo nh√£n')

    for i, count in enumerate(counts):
        plt.text(i, count, str(count), ha='center', va='bottom')

    # ====== L∆ØU FILE PNG ======
    os.makedirs(save_dir, exist_ok=True)
    filename = 'word_occurrence.png'
    filepath = os.path.join(save_dir, filename)

    plt.savefig(filepath, dpi=dpi, bbox_inches='tight')
    print(f'ƒê√£ l∆∞u bi·ªÉu ƒë·ªì t·∫°i: {filepath}')

    plt.show()
    plt.close()
